{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6363302e",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "# ğŸš€ Simple ML Template - Clean Data Fast\n",
    "\n",
    "## Purpose\n",
    "Quick template to get from raw data to clean, model-ready data using our preprocessing classes.\n",
    "\n",
    "**Steps:**\n",
    "1. Configure preprocessing parameters\n",
    "2. Run ProductionCarMatcher + DataPreprocessor  \n",
    "3. Get clean X_train, X_test, y_train, y_test\n",
    "4. Start modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bd576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SIMPLE ML TEMPLATE - FAST CLEAN DATA\n",
      "=============================================\n",
      " Configuration: {'random_state': 42, 'target_column': 'price', 'outlier_removal': True, 'feature_scaling': True, 'encoding_method': 'mean', 'missing_strategy': 'smart', 'log_transform_mileage': True, 'convert_year_to_age': True, 'normalize_paint': True, 'normalize_engine': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import kagglehub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load preprocessing classes\n",
    "os.chdir('/Users/leonardodicaterina/Documents/GitHub/ML_group_45')\n",
    "from utils.preprocessing.CarDatabase import ProductionCarMatcher, create_optimized_database\n",
    "from utils.preprocessing.Preprocessor_divided import DataPreprocessor\n",
    "\n",
    "print(\" SIMPLE ML TEMPLATE - FAST CLEAN DATA\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# CONFIGURATION - Change these as needed\n",
    "CONFIG = {\n",
    "    'random_state': 42,\n",
    "    'target_column': 'price',\n",
    "    \n",
    "    # Preprocessing options\n",
    "    'outlier_removal': True,          # Remove outliers?\n",
    "    'feature_scaling': True,          # Scale features?\n",
    "    'encoding_method': 'mean',        # 'mean', 'onehot'\n",
    "    'missing_strategy': 'smart',      # 'smart', 'median', 'mean'\n",
    "    \n",
    "    # Feature transformations\n",
    "    'log_transform_mileage': True,    # Log transform mileage?\n",
    "    'convert_year_to_age': True,      # Convert year to car age?\n",
    "    'normalize_paint': True,          # Normalize paint quality to 0-1?\n",
    "    'normalize_engine': True,         # Convert engine size units?\n",
    "}\n",
    "\n",
    "print(f\" Configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5245f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ SIMPLE ML TEMPLATE - FAST CLEAN DATA\n",
      "=============================================\n",
      "ğŸ“‹ Configuration: {'random_state': 42, 'target_column': 'price', 'outlier_removal': True, 'feature_scaling': True, 'encoding_method': 'mean', 'missing_strategy': 'smart', 'log_transform_mileage': True, 'convert_year_to_age': True, 'normalize_paint': True, 'normalize_engine': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import kagglehub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load preprocessing classes\n",
    "os.chdir('/Users/leonardodicaterina/Documents/GitHub/ML_group_45')\n",
    "from utils.preprocessing.CarDatabase import ProductionCarMatcher, create_optimized_database\n",
    "from utils.preprocessing.Preprocessor_divided import DataPreprocessor\n",
    "\n",
    "print(\"ğŸš€ SIMPLE ML TEMPLATE - FAST CLEAN DATA\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# CONFIGURATION - Change these as needed\n",
    "CONFIG = {\n",
    "    'random_state': 42,\n",
    "    'target_column': 'price',\n",
    "    \n",
    "    # Preprocessing options\n",
    "    'outlier_removal': True,          # Remove outliers?\n",
    "    'feature_scaling': True,          # Scale features?\n",
    "    'encoding_method': 'mean',        # 'mean', 'onehot'\n",
    "    'missing_strategy': 'smart',      # 'smart', 'median', 'mean'\n",
    "    \n",
    "    # Feature transformations\n",
    "    'log_transform_mileage': True,    # Log transform mileage?\n",
    "    'convert_year_to_age': True,      # Convert year to car age?\n",
    "    'normalize_paint': True,          # Normalize paint quality to 0-1?\n",
    "    'normalize_engine': True,         # Convert engine size units?\n",
    "}\n",
    "\n",
    "print(f\"ğŸ“‹ Configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc54a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ STEP 1: Loading raw data...\n",
      "   Train: (75973, 14), Test: (32567, 13)\n",
      "\n",
      "ğŸ”„ STEP 2: Brand standardization...\n",
      "Analyzing word frequencies...\n",
      "Created optimized database with 146 makes\n",
      "   âœ… Brands: 72 â†’ 12\n",
      "\n",
      "ğŸ”„ STEP 3: Feature preprocessing...\n",
      "âœ“ Fitting pipeline for 'mileage'\n",
      "âœ“ Fitting pipeline for 'year'\n",
      "âœ“ Fitting pipeline for 'engineSize'\n",
      "âœ“ Fitting pipeline for 'tax'\n",
      "âœ“ Fitting pipeline for 'mpg'\n",
      "âœ“ Fitting pipeline for 'paintQuality%'\n",
      "âœ“ Fitting pipeline for 'previousOwners'\n",
      "âœ“ Fitting pipeline for 'hasDamage'\n",
      "âœ“ Fitting pipeline for 'Brand_cleaned'\n",
      "âœ“ Fitting pipeline for 'transmission'\n",
      "âœ“ Fitting pipeline for 'fuelType'\n",
      "âœ“ Transforming 'mileage'\n",
      "âœ“ Transforming 'year'\n",
      "âœ“ Transforming 'engineSize'\n",
      "âœ“ Transforming 'tax'\n",
      "âœ“ Transforming 'mpg'\n",
      "âœ“ Transforming 'paintQuality%'\n",
      "âœ“ Transforming 'previousOwners'\n",
      "âœ“ Transforming 'hasDamage'\n",
      "âœ“ Transforming 'Brand_cleaned'\n",
      "âœ“ Transforming 'transmission'\n",
      "âœ“ Transforming 'fuelType'\n",
      "âœ“ Transforming 'mileage'\n",
      "âœ“ Transforming 'year'\n",
      "âœ“ Transforming 'engineSize'\n",
      "âœ“ Transforming 'tax'\n",
      "âœ“ Transforming 'mpg'\n",
      "âœ“ Transforming 'paintQuality%'\n",
      "âœ“ Transforming 'previousOwners'\n",
      "âœ“ Transforming 'hasDamage'\n",
      "âœ“ Transforming 'Brand_cleaned'\n",
      "âœ“ Transforming 'transmission'\n",
      "âœ“ Transforming 'fuelType'\n",
      "   âœ… Features: 11 â†’ 14\n",
      "   âœ… Missing values: 3038\n",
      "\n",
      "âœ… CLEAN DATA READY!\n",
      "   X_train: (75973, 14)\n",
      "   X_test: (32567, 14)\n",
      "   Features: ['carID', 'Brand', 'model', 'year', 'transmission', 'mileage', 'fuelType', 'tax', 'mpg', 'engineSize', 'paintQuality%', 'previousOwners', 'hasDamage', 'Brand_cleaned']\n",
      "\n",
      "ğŸš€ Ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(config=CONFIG):\n",
    "    \"\"\"\n",
    "    Complete pipeline: raw data â†’ clean data ready for ML\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ”„ STEP 1: Loading raw data...\")\n",
    "    # Load datasets\n",
    "    train_data = pd.read_csv('Data/train.csv')\n",
    "    test_data = pd.read_csv('Data/test.csv')\n",
    "    print(f\"   Train: {train_data.shape}, Test: {test_data.shape}\")\n",
    "    \n",
    "    print(\"\\nğŸ”„ STEP 2: Brand standardization...\")\n",
    "    # Download car database\n",
    "    try:\n",
    "        path = kagglehub.dataset_download(\"bourzamraid/global-car-make-and-model-list\")\n",
    "        with open(os.path.join(path, 'vehicle models.json'), 'r') as f:\n",
    "            kaggle_data = json.load(f)\n",
    "        \n",
    "        # Create matcher and clean brands\n",
    "        optimized_db = create_optimized_database(kaggle_data, max_model_words=3)\n",
    "        matcher = ProductionCarMatcher(optimized_db)\n",
    "        \n",
    "        # Clean brands\n",
    "        train_data['Brand_cleaned'] = [matcher.find_best_make_match(brand)[0] for brand in train_data['Brand']]\n",
    "        test_data['Brand_cleaned'] = [matcher.find_best_make_match(brand)[0] for brand in test_data['Brand']]\n",
    "        \n",
    "        print(f\"   âœ… Brands: {train_data['Brand'].nunique()} â†’ {train_data['Brand_cleaned'].nunique()}\")\n",
    "    except:\n",
    "        print(\"   âš ï¸ Using original brands (database download failed)\")\n",
    "        train_data['Brand_cleaned'] = train_data['Brand']\n",
    "        test_data['Brand_cleaned'] = test_data['Brand']\n",
    "    \n",
    "    print(\"\\nğŸ”„ STEP 3: Feature preprocessing...\")\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = DataPreprocessor(target_column=config['target_column'])\n",
    "    \n",
    "    # Define transformations\n",
    "    def log_transform(x):\n",
    "        return np.log1p(np.abs(x)) if config['log_transform_mileage'] else x\n",
    "    \n",
    "    def year_to_age(year_series):\n",
    "        return 2025 - year_series if config['convert_year_to_age'] else year_series\n",
    "    \n",
    "    def normalize_paint(paint_series):\n",
    "        return np.clip(paint_series, 0, 100) / 100 if config['normalize_paint'] else paint_series\n",
    "    \n",
    "    def normalize_engine(engine_series):\n",
    "        if config['normalize_engine']:\n",
    "            result = engine_series.copy()\n",
    "            small_engines = engine_series <= 10\n",
    "            result[small_engines] = engine_series[small_engines] * 1000\n",
    "            return result\n",
    "        return engine_series\n",
    "    \n",
    "    # Configure features\n",
    "    feature_configs = {\n",
    "        'mileage': {\n",
    "            'missing_strategy': 'median',\n",
    "            'outlier_method': 'iqr' if config['outlier_removal'] else None,\n",
    "            'transform_func': log_transform if config['log_transform_mileage'] else None,\n",
    "            'scaling_method': 'standard' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'year': {\n",
    "            'missing_strategy': 'mean',\n",
    "            'transform_func': year_to_age if config['convert_year_to_age'] else None,\n",
    "            'scaling_method': 'minmax' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'engineSize': {\n",
    "            'missing_strategy': 1600,\n",
    "            'transform_func': normalize_engine if config['normalize_engine'] else None,\n",
    "            'scaling_method': 'robust' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'tax': {\n",
    "            'missing_strategy': 'median',\n",
    "            'scaling_method': 'standard' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'mpg': {\n",
    "            'missing_strategy': 'median',\n",
    "            'outlier_method': 'iqr' if config['outlier_removal'] else None,\n",
    "            'scaling_method': 'standard' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'paintQuality%': {\n",
    "            'missing_strategy': 'median',\n",
    "            'transform_func': normalize_paint if config['normalize_paint'] else None,\n",
    "            'scaling_method': 'minmax' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'previousOwners': {\n",
    "            'missing_strategy': 'median',\n",
    "            'transform_func': lambda x: np.log1p(np.abs(np.floor(x))),\n",
    "            'scaling_method': 'standard' if config['feature_scaling'] else None\n",
    "        },\n",
    "        'hasDamage': {\n",
    "            'missing_strategy': 1,\n",
    "            'scaling_method': None\n",
    "        },\n",
    "        'Brand_cleaned': {\n",
    "            'missing_strategy': 'mode',\n",
    "            'encoding_method': config['encoding_method']\n",
    "        },\n",
    "        'transmission': {\n",
    "            'missing_strategy': 'mode',\n",
    "            'encoding_method': config['encoding_method']\n",
    "        },\n",
    "        'fuelType': {\n",
    "            'missing_strategy': 'mode',\n",
    "            'encoding_method': config['encoding_method']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add features to preprocessor\n",
    "    for feature, feature_config in feature_configs.items():\n",
    "        if feature in train_data.columns:\n",
    "            preprocessor.add_feature_pipeline(feature, **feature_config)\n",
    "    \n",
    "    # Fit and transform\n",
    "    preprocessor.fit(train_data)\n",
    "    X_train, y_train = preprocessor.transform(train_data)\n",
    "    X_test, y_test = preprocessor.transform(test_data)\n",
    "    \n",
    "    print(f\"   âœ… Features: {len(feature_configs)} â†’ {X_train.shape[1]}\")\n",
    "    print(f\"   âœ… Missing values: {X_train.isnull().sum().sum()}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, preprocessor\n",
    "\n",
    "# Run preprocessing\n",
    "X_train, X_test, y_train, y_test, preprocessor = load_and_preprocess_data()\n",
    "\n",
    "print(f\"\\nâœ… CLEAN DATA READY!\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "print(f\"   Features: {list(X_train.columns)}\")\n",
    "print(f\"\\nğŸš€ Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36935b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” QUICK VALIDATION\n",
      "====================\n",
      "âœ… Data shapes match: True\n",
      "âœ… No missing values: False\n",
      "âœ… Target is numeric: True\n",
      "âœ… Features are numeric: False\n",
      "\n",
      "ğŸ“Š Quick Stats:\n",
      "   Samples: 75,973\n",
      "   Features: 14\n",
      "   Target range: [450, 159999]\n"
     ]
    }
   ],
   "source": [
    "# Quick data validation\n",
    "print(\"ğŸ” QUICK VALIDATION\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "print(f\"âœ… Data shapes match: {X_train.shape[1] == X_test.shape[1]}\")\n",
    "print(f\"âœ… No missing values: {X_train.isnull().sum().sum() == 0}\")\n",
    "print(f\"âœ… Target is numeric: {y_train.dtype in ['int64', 'float64']}\")\n",
    "print(f\"âœ… Features are numeric: {X_train.select_dtypes(include=[np.number]).shape[1] == X_train.shape[1]}\")\n",
    "\n",
    "# Quick stats\n",
    "print(f\"\\nğŸ“Š Quick Stats:\")\n",
    "print(f\"   Samples: {len(X_train):,}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"   Target range: [{y_train.min():.0f}, {y_train.max():.0f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00552f",
   "metadata": {},
   "source": [
    "## ğŸ¯ Data is Clean - Start Modeling!\n",
    "\n",
    "Your data is now clean and ready. Here's what you have:\n",
    "\n",
    "- **X_train, X_test**: Feature matrices (scaled, encoded, no missing values)\n",
    "- **y_train, y_test**: Target vectors  \n",
    "- **preprocessor**: Fitted preprocessor (for new data)\n",
    "\n",
    "**Next steps:** Add your ML models below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cfe64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ QUICK MODEL TEST:\n",
      "   Random Forest RMSE: 2832\n",
      "   Random Forest RÂ²: 0.917\n",
      "\n",
      "ğŸ‘† Replace this with your models!\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE: Quick model test\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# split train and valdation\n",
    "X_train_, X_val_ = X_train.iloc[:int(0.8*len(X_train))], X_train.iloc[int(0.8*len(X_train)):]\n",
    "y_train_ , y_val_ = y_train.iloc[:int(0.8*len(y_train))], y_train.iloc[int(0.8*len(y_train)):]\n",
    "X_train_ = X_train_[numerical_features]\n",
    "X_val_ = X_val_[numerical_features]\n",
    "# Quick model test\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "predictions = model.predict(X_val_)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_, predictions))\n",
    "r2 = r2_score(y_val_, predictions)\n",
    "\n",
    "print(f\"ğŸ”¥ QUICK MODEL TEST:\")\n",
    "print(f\"   Random Forest RMSE: {rmse:.0f}\")\n",
    "print(f\"   Random Forest RÂ²: {r2:.3f}\")\n",
    "print(f\"\\nğŸ‘† Replace this with your models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba755d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19393.22, 22720.85, 13948.53, ..., 34663.54, 19656.24, 14220.67])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
