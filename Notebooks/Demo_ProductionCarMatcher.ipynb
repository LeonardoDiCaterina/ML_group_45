{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfcdba1",
   "metadata": {},
   "source": [
    "# ProductionCarMatcher Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `ProductionCarMatcher` provides intelligent car make and model standardization using a comprehensive Kaggle dataset as reference. It handles real-world data inconsistencies, typos, and variations commonly found in automotive datasets.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Comprehensive Database**: Built from Kaggle's global car dataset\n",
    "- **Real Data Testing**: Uses actual train data for validation\n",
    "- **Fuzzy Matching**: Handles typos and abbreviations\n",
    "- **Production Ready**: Batch processing for large datasets\n",
    "- **Quality Metrics**: Confidence scoring and statistics\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "1. **Reference Database**: Kaggle Global Car Make and Model List\n",
    "2. **Test Data**: Our car price prediction training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78896df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Kaggle car dataset...\n",
      "Dataset downloaded to: /Users/leonardodicaterina/.cache/kagglehub/datasets/bourzamraid/global-car-make-and-model-list/versions/1/vehicle models.json\n",
      "Loading vehicle models database...\n",
      "Kaggle database loaded: 144 manufacturers\n",
      "Loading train dataset...\n",
      "Train data loaded: (75973, 14)\n",
      "\n",
      "Train data sample:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brand",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3fc21f72-0f66-449d-9b76-91beb10c701c",
       "rows": [
        [
         "0",
         "VW",
         "2016.0",
         "22290"
        ],
        [
         "1",
         "Toyota",
         "2019.0",
         "13790"
        ],
        [
         "2",
         "Audi",
         "2019.0",
         "24990"
        ],
        [
         "3",
         "Ford",
         "2018.0",
         "12500"
        ],
        [
         "4",
         "BMW",
         "2019.0",
         "22995"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VW</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>22290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>13790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>24990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>22995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand    year  price\n",
       "0      VW  2016.0  22290\n",
       "1  Toyota  2019.0  13790\n",
       "2    Audi  2019.0  24990\n",
       "3    Ford  2018.0  12500\n",
       "4     BMW  2019.0  22995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique brands in train data: 72\n",
      "Sample brands: ['Ford', 'Mercedes', 'VW', 'Opel', 'BMW']\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import required libraries for data download\n",
    "import kagglehub\n",
    "\n",
    "# Load our custom classes\n",
    "os.chdir('/Users/leonardodicaterina/Documents/GitHub/ML_group_45')\n",
    "from utils.preprocessing.CarDatabase import ProductionCarMatcher, create_optimized_database\n",
    "\n",
    "# Download latest Kaggle car dataset\n",
    "print(\"Downloading Kaggle car dataset...\")\n",
    "path = kagglehub.dataset_download(\"bourzamraid/global-car-make-and-model-list\")\n",
    "file_path = os.path.join(path, 'vehicle models.json')\n",
    "print(f\"Dataset downloaded to: {file_path}\")\n",
    "\n",
    "# Load the comprehensive car database\n",
    "print(\"Loading vehicle models database...\")\n",
    "with open(file_path, 'r') as f:\n",
    "    kaggle_car_data = json.load(f)\n",
    "\n",
    "    \n",
    "print(f\"Kaggle database loaded: {len(kaggle_car_data)} manufacturers\")\n",
    "\n",
    "# Load our train data\n",
    "print(\"Loading train dataset...\")\n",
    "train_data = pd.read_csv('Data/train.csv')\n",
    "print(f\"Train data loaded: {train_data.shape}\")\n",
    "\n",
    "# Show sample of what we're working with\n",
    "print(f\"\\nTrain data sample:\")\n",
    "display(train_data[['Brand', 'year', 'price']].head())\n",
    "\n",
    "print(f\"\\nUnique brands in train data: {train_data['Brand'].nunique()}\")\n",
    "print(f\"Sample brands: {train_data['Brand'].value_counts().head().index.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d290b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE CREATION & MATCHER INITIALIZATION\n",
      "==================================================\n",
      "Creating optimized database...\n",
      "Analyzing word frequencies...\n",
      "Created optimized database with 146 makes\n",
      "Database optimization complete!\n",
      "  Original manufacturers: 144\n",
      "  Optimized manufacturers: 146\n",
      "Initializing ProductionCarMatcher...\n",
      "\n",
      "Sample database entries:\n",
      "  am general:\n",
      "    Canonical: am general\n",
      "    Aliases: []...\n",
      "    Models: 3 models\n",
      "    Sample models: ['dj po', 'fj8c post', 'post office']...\n",
      "\n",
      "  asc incorporated:\n",
      "    Canonical: asc incorporated\n",
      "    Aliases: []...\n",
      "    Models: 1 models\n",
      "    Sample models: ['gnx']...\n",
      "\n",
      "  acura:\n",
      "    Canonical: acura\n",
      "    Aliases: []...\n",
      "    Models: 47 models\n",
      "    Sample models: ['22cl30cl', '23cl30cl', '25tl']...\n",
      "\n",
      "  alfa romeo:\n",
      "    Canonical: alfa romeo\n",
      "    Aliases: []...\n",
      "    Models: 12 models\n",
      "    Sample models: ['164', 'c spider', 'giulia']...\n",
      "\n",
      "  american motors corporation:\n",
      "    Canonical: american motors corporation\n",
      "    Aliases: []...\n",
      "    Models: 4 models\n",
      "    Sample models: ['eagle', 'eagle 4dr', 'eagle 4wd']...\n",
      "\n",
      "Matcher ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Create optimized database and initialize matcher\n",
    "print(\"DATABASE CREATION & MATCHER INITIALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "# Create optimized database\n",
    "print(\"Creating optimized database...\")\n",
    "optimized_db = create_optimized_database(kaggle_car_data, max_model_words=2)\n",
    "\n",
    "print(f\"Database optimization complete!\")\n",
    "print(f\"  Original manufacturers: {len(kaggle_car_data)}\")\n",
    "print(f\"  Optimized manufacturers: {len(optimized_db)}\")\n",
    "\n",
    "# Initialize matcher\n",
    "print(\"Initializing ProductionCarMatcher...\")\n",
    "matcher = ProductionCarMatcher(optimized_db)\n",
    "\n",
    "# Show sample database entries\n",
    "print(f\"\\nSample database entries:\")\n",
    "sample_makes = list(optimized_db.keys())[:5]\n",
    "for make in sample_makes:\n",
    "    entry = optimized_db[make]\n",
    "    print(f\"  {make}:\")\n",
    "    print(f\"    Canonical: {entry['canonical_name']}\")\n",
    "    print(f\"    Aliases: {entry['aliases'][:3]}...\")\n",
    "    print(f\"    Models: {len(entry['models'])} models\")\n",
    "    print(f\"    Sample models: {entry['models'][:3]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"Matcher ready for use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab826e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDIVIDUAL MATCHING EXAMPLES\n",
      "========================================\n",
      "\n",
      "Make Matching Results:\n",
      "--------------------\n",
      "✓ 'BMW' → 'bmw' (confidence: 100%)\n",
      "✓ 'bmw' → 'bmw' (confidence: 100%)\n",
      "✓ 'B M W' → 'bmw' (confidence: 75.0%)\n",
      "✓ 'Beemer' → 'bmw' (confidence: 100%)\n",
      "✓ 'Mercedes' → 'mercedes-benz' (confidence: 100%)\n",
      "✓ 'Mercedes-Benz' → 'mercedes-benz' (confidence: 100%)\n",
      "✓ 'Merc' → 'mercedes-benz' (confidence: 100%)\n",
      "✓ 'Volkswagen' → 'volkswagen' (confidence: 100%)\n",
      "✓ 'VW' → 'volkswagen' (confidence: 100%)\n",
      "✓ 'Audi' → 'audi' (confidence: 100%)\n",
      "✓ 'Toyata' → 'toyota' (confidence: 85.71428571428572%)\n",
      "✓ 'Hyundai' → 'hyundai' (confidence: 100%)\n",
      "✓ 'Hundai' → 'hyundai' (confidence: 100%)\n",
      "\n",
      "Model Matching Results:\n",
      "--------------------\n",
      "✗ BMW '3 Series' → 'None' (confidence: 0%)\n",
      "✗ BMW '3series' → 'None' (confidence: 0%)\n",
      "✗ BMW 'BMW 3 Series' → 'None' (confidence: 0%)\n",
      "✗ BMW 'three series' → 'None' (confidence: 0%)\n",
      "✗ BMW 'X5' → 'None' (confidence: 0%)\n",
      "✗ Audi 'A4' → 'None' (confidence: 0%)\n",
      "✗ Audi 'a4' → 'None' (confidence: 0%)\n",
      "✗ Mercedes-Benz 'C-Class' → 'None' (confidence: 0%)\n",
      "✗ Mercedes-Benz 'c class' → 'None' (confidence: 0%)\n",
      "✗ Toyota 'Corolla' → 'None' (confidence: 0%)\n",
      "✗ Toyota 'Corrolla' → 'None' (confidence: 0%)\n",
      "✗ Volkswagen 'Golf' → 'None' (confidence: 0%)\n",
      "✗ Ford 'Fiesta' → 'None' (confidence: 0%)\n",
      "\n",
      "Key Observations:\n",
      "  • Fuzzy matching handles typos and variations\n",
      "  • Brand constraints prevent cross-brand confusion\n",
      "  • Numeric models (3 Series, A4) handled intelligently\n",
      "  • Case and spacing variations normalized automatically\n"
     ]
    }
   ],
   "source": [
    "# Individual matching examples\n",
    "print(\"INDIVIDUAL MATCHING EXAMPLES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test make matching with various inputs\n",
    "make_tests = [\n",
    "    \"BMW\",           # Exact match\n",
    "    \"bmw\",           # Case variation\n",
    "    \"B M W\",         # Spacing variation\n",
    "    \"Beemer\",        # Common nickname\n",
    "    \"Mercedes\",      # Partial brand name\n",
    "    \"Mercedes-Benz\", # Full brand name\n",
    "    \"Merc\",          # Abbreviation\n",
    "    \"Volkswagen\",    # Full name\n",
    "    \"VW\",            # Common abbreviation\n",
    "    \"Audi\",          # Simple exact match\n",
    "    \"Toyata\",        # Typo (should match Toyota)\n",
    "    \"Hyundai\",       # Exact match\n",
    "    \"Hundai\"         # Common misspelling\n",
    "]\n",
    "\n",
    "print(\"\\nMake Matching Results:\")\n",
    "print(\"-\" * 20)\n",
    "for test_make in make_tests:\n",
    "    match, confidence = matcher.find_best_make_match(test_make)\n",
    "    status = \"✓\" if confidence >= 70 else \"✗\"\n",
    "    print(f\"{status} '{test_make}' → '{match}' (confidence: {confidence}%)\")\n",
    "\n",
    "# Test model matching with specific makes\n",
    "print(f\"\\nModel Matching Results:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "model_tests = [\n",
    "    (\"BMW\", \"3 Series\"),        # Exact match\n",
    "    (\"BMW\", \"3series\"),         # No space\n",
    "    (\"BMW\", \"BMW 3 Series\"),    # Redundant make\n",
    "    (\"BMW\", \"three series\"),    # Written out number\n",
    "    (\"BMW\", \"X5\"),              # SUV model\n",
    "    (\"Audi\", \"A4\"),            # Simple alphanumeric\n",
    "    (\"Audi\", \"a4\"),            # Case variation\n",
    "    (\"Mercedes-Benz\", \"C-Class\"), # Hyphenated model\n",
    "    (\"Mercedes-Benz\", \"c class\"), # Space instead of hyphen\n",
    "    (\"Toyota\", \"Corolla\"),      # Standard model\n",
    "    (\"Toyota\", \"Corrolla\"),     # Typo\n",
    "    (\"Volkswagen\", \"Golf\"),     # Simple name\n",
    "    (\"Ford\", \"Fiesta\"),         # Another simple name\n",
    "]\n",
    "\n",
    "for make, model in model_tests:\n",
    "    result = matcher.find_best_model_match(model, make)\n",
    "    if result:\n",
    "        match, confidence, matched_make = result\n",
    "        status = \"✓\" if confidence >= 70 else \"✗\"\n",
    "        print(f\"{status} {make} '{model}' → '{match}' (confidence: {confidence}%)\")\n",
    "    else:\n",
    "        print(f\"✗ {make} '{model}' → No match found\")\n",
    "\n",
    "print(f\"\\nKey Observations:\")\n",
    "print(f\"  • Fuzzy matching handles typos and variations\")\n",
    "print(f\"  • Brand constraints prevent cross-brand confusion\")\n",
    "print(f\"  • Numeric models (3 Series, A4) handled intelligently\")\n",
    "print(f\"  • Case and spacing variations normalized automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7b4409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL DATA CLEANING DEMO\n",
      "========================================\n",
      "Analyzing train data brands...\n",
      "Top 10 brands in train data:\n",
      "Brand\n",
      "Ford        14808\n",
      "Mercedes    10754\n",
      "VW           9780\n",
      "Opel         8645\n",
      "BMW          6968\n",
      "Audi         6749\n",
      "Toyota       4289\n",
      "Skoda        3973\n",
      "Hyundai      3066\n",
      "FORD          316\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Brand distribution analysis:\n",
      "  Total unique brands: 72\n",
      "  Single occurrence brands: 4\n",
      "  Low frequency brands (<5): 22\n",
      "\n",
      "Cleaning brands with ProductionCarMatcher...\n",
      "\n",
      "Cleaning Results:\n",
      "  Original unique brands: 72\n",
      "  Cleaned unique brands: 12\n",
      "  Brands consolidated: 60\n",
      "  Average confidence: 98.0%\n",
      "  High confidence matches (≥90%): 74452\n",
      "  Low confidence matches (<70%): 1521\n",
      "\n",
      "Before vs After Comparison:\n",
      "Top 10 cleaned brands:\n",
      "Brand_cleaned\n",
      "ford                        16056\n",
      "mercedes-benz               11674\n",
      "volkswagen                   9973\n",
      "opel                         9348\n",
      "bmw                          7600\n",
      "audi                         7325\n",
      "toyota                       4622\n",
      "skoda                        4303\n",
      "hyundai                      3336\n",
      "avanti motor corporation      204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Brand Cleaning Examples:\n",
      "✓ 'VW' → 'volkswagen' (100.0%)\n",
      "✓ 'Toyota' → 'toyota' (100.0%)\n",
      "✓ 'Audi' → 'audi' (100.0%)\n",
      "✓ 'Ford' → 'ford' (100.0%)\n",
      "✓ 'BMW' → 'bmw' (100.0%)\n",
      "✓ 'Skoda' → 'skoda' (100.0%)\n",
      "✓ 'Opel' → 'opel' (100.0%)\n",
      "✓ 'Mercedes' → 'mercedes-benz' (100.0%)\n",
      "✓ 'FOR' → 'ford' (100.0%)\n",
      "✓ 'mercedes' → 'mercedes-benz' (100.0%)\n",
      "✓ 'Hyundai' → 'hyundai' (100.0%)\n",
      "✓ 'w' → 'bmw' (100.0%)\n",
      "✓ 'ord' → 'ford' (100.0%)\n",
      "✓ 'MW' → 'bmw' (100.0%)\n",
      "✓ 'bmw' → 'bmw' (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Real data cleaning with actual train dataset\n",
    "print(\"REAL DATA CLEANING DEMO\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Analyze current state of train data brands\n",
    "print(\"Analyzing train data brands...\")\n",
    "brand_counts = train_data['Brand'].value_counts()\n",
    "print(f\"Top 10 brands in train data:\")\n",
    "print(brand_counts.head(10))\n",
    "\n",
    "print(f\"\\nBrand distribution analysis:\")\n",
    "print(f\"  Total unique brands: {len(brand_counts)}\")\n",
    "print(f\"  Single occurrence brands: {sum(brand_counts == 1)}\")\n",
    "print(f\"  Low frequency brands (<5): {sum(brand_counts < 5)}\")\n",
    "\n",
    "# Clean the brands using our matcher\n",
    "print(f\"\\nCleaning brands with ProductionCarMatcher...\")\n",
    "cleaned_brands = []\n",
    "brand_confidences = []\n",
    "unmatched_brands = []\n",
    "\n",
    "for brand in train_data['Brand']:\n",
    "    match, confidence = matcher.find_best_make_match(brand)\n",
    "    cleaned_brands.append(match)\n",
    "    brand_confidences.append(confidence)\n",
    "    \n",
    "    if confidence < 70:\n",
    "        unmatched_brands.append(brand)\n",
    "\n",
    "# Add cleaned data to train dataset\n",
    "train_data_cleaned = train_data.copy()\n",
    "train_data_cleaned['Brand_cleaned'] = cleaned_brands\n",
    "train_data_cleaned['Brand_confidence'] = brand_confidences\n",
    "\n",
    "# Analyze cleaning results\n",
    "print(f\"\\nCleaning Results:\")\n",
    "print(f\"  Original unique brands: {train_data['Brand'].nunique()}\")\n",
    "print(f\"  Cleaned unique brands: {train_data_cleaned['Brand_cleaned'].nunique()}\")\n",
    "print(f\"  Brands consolidated: {train_data['Brand'].nunique() - train_data_cleaned['Brand_cleaned'].nunique()}\")\n",
    "print(f\"  Average confidence: {np.mean(brand_confidences):.1f}%\")\n",
    "print(f\"  High confidence matches (≥90%): {sum(np.array(brand_confidences) >= 90)}\")\n",
    "print(f\"  Low confidence matches (<70%): {len(unmatched_brands)}\")\n",
    "\n",
    "# Show before/after comparison\n",
    "print(f\"\\nBefore vs After Comparison:\")\n",
    "cleaned_brand_counts = train_data_cleaned['Brand_cleaned'].value_counts()\n",
    "print(f\"Top 10 cleaned brands:\")\n",
    "print(cleaned_brand_counts.head(10))\n",
    "\n",
    "# Show specific examples of brand cleaning\n",
    "print(f\"\\nBrand Cleaning Examples:\")\n",
    "examples = train_data_cleaned[['Brand', 'Brand_cleaned', 'Brand_confidence']].drop_duplicates().head(15)\n",
    "for _, row in examples.iterrows():\n",
    "    confidence = row['Brand_confidence']\n",
    "    status = \"✓\" if confidence >= 70 else \"✗\"\n",
    "    print(f\"{status} '{row['Brand']}' → '{row['Brand_cleaned']}' ({confidence}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec984de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDGE CASES & PERFORMANCE ANALYSIS\n",
      "========================================\n",
      "Testing edge cases:\n",
      "--------------------\n",
      "✗ '' → 'None' (0%)\n",
      "✗ 'None' → 'None' (0%)\n",
      "✗ '   ' → 'None' (0%)\n",
      "✗ '123' → 'None' (0%)\n",
      "✗ '!@#$' → 'None' (0%)\n",
      "✓ 'Unknown Brand' → 'kandi' (75.0%)\n",
      "✓ 'Tesla Model S' → 'tesla' (100.0%)\n",
      "✓ 'BMW3Series' → 'bmw' (100.0%)\n",
      "✓ 'Mer ce des' → 'mercedes-benz' (88.88888888888889%)\n",
      "✓ 'VOLKSWAGEN' → 'volkswagen' (100%)\n",
      "✓ 'b.m.w' → 'bmw' (100%)\n",
      "✓ 'ford-fiesta' → 'ford' (100.0%)\n",
      "\n",
      "Low Confidence Analysis:\n",
      "--------------------\n",
      "Brands with low confidence (<70%):\n",
      "  'nan' → 'None' (0.0%)\n",
      "\n",
      "Performance Metrics:\n",
      "--------------------\n",
      "Confidence distribution:\n",
      "  Very Low (0-50%): 0 (0.0%)\n",
      "  Low (50-70%): 0 (0.0%)\n",
      "  Medium (70-85%): 0 (0.0%)\n",
      "  High (85-95%): 0 (0.0%)\n",
      "  Very High (95-100%): 74,452 (98.0%)\n",
      "\n",
      "Brand Consolidation Analysis:\n",
      "--------------------\n",
      "Top brands with most variants consolidated:\n",
      "1. mercedes-benz (11674 cars)\n",
      "   Consolidated 9 variants: ['Mercedes', 'mercedes', 'Mercede', 'MERCEDES', 'ercedes', 'mercede', 'ERCEDES', 'ercede', 'MERCEDE']\n",
      "\n",
      "2. audi (7325 cars)\n",
      "   Consolidated 9 variants: ['Audi', 'udi', 'AUDI', 'audi', 'Aud', 'aud', 'UDI', 'ud', 'AUD']\n",
      "\n",
      "3. skoda (4303 cars)\n",
      "   Consolidated 9 variants: ['Skoda', 'koda', 'skoda', 'SKODA', 'Skod', 'kod', 'SKOD', 'KODA', 'skod']\n",
      "\n",
      "4. ford (16056 cars)\n",
      "   Consolidated 8 variants: ['Ford', 'FOR', 'ord', 'For', 'FORD', 'ford', 'for', 'ORD']\n",
      "\n",
      "5. opel (9348 cars)\n",
      "   Consolidated 8 variants: ['Opel', 'Ope', 'opel', 'pel', 'OPEL', 'PEL', 'OPE', 'ope']\n",
      "\n",
      "Total consolidation impact:\n",
      "  Brands reduced from 72 to 12\n",
      "  Reduction: 60 brands (-83.3%)\n"
     ]
    }
   ],
   "source": [
    "# Edge cases and performance analysis\n",
    "print(\"EDGE CASES & PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test edge cases\n",
    "edge_cases = [\n",
    "    \"\",              # Empty string\n",
    "    None,            # None value\n",
    "    \"   \",           # Whitespace only\n",
    "    \"123\",           # Numbers only\n",
    "    \"!@#$\",          # Special characters only\n",
    "    \"Unknown Brand\", # Completely unknown\n",
    "    \"Tesla Model S\", # Model in make field\n",
    "    \"BMW3Series\",    # No spaces\n",
    "    \"Mer ce des\",    # Extra spaces\n",
    "    \"VOLKSWAGEN\",    # All caps\n",
    "    \"b.m.w\",         # Periods\n",
    "    \"ford-fiesta\",   # Hyphenated\n",
    "]\n",
    "\n",
    "print(\"Testing edge cases:\")\n",
    "print(\"-\" * 20)\n",
    "for test_case in edge_cases:\n",
    "    try:\n",
    "        match, confidence = matcher.find_best_make_match(test_case)\n",
    "        status = \"✓\" if confidence >= 70 else \"⚠\" if confidence >= 50 else \"✗\"\n",
    "        print(f\"{status} '{test_case}' → '{match}' ({confidence}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ '{test_case}' → Error: {str(e)}\")\n",
    "\n",
    "# Analyze low confidence matches from real data\n",
    "print(f\"\\nLow Confidence Analysis:\")\n",
    "print(\"-\" * 20)\n",
    "low_confidence = train_data_cleaned[train_data_cleaned['Brand_confidence'] < 70]\n",
    "if len(low_confidence) > 0:\n",
    "    print(f\"Brands with low confidence (<70%):\")\n",
    "    low_conf_examples = low_confidence[['Brand', 'Brand_cleaned', 'Brand_confidence']].drop_duplicates()\n",
    "    for _, row in low_conf_examples.head(10).iterrows():\n",
    "        print(f\"  '{row['Brand']}' → '{row['Brand_cleaned']}' ({row['Brand_confidence']}%)\")\n",
    "else:\n",
    "    print(\"No low confidence matches found!\")\n",
    "\n",
    "# Performance metrics\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(\"-\" * 20)\n",
    "confidence_distribution = pd.cut(train_data_cleaned['Brand_confidence'], \n",
    "                                bins=[0, 50, 70, 85, 95, 100], \n",
    "                                labels=['Very Low (0-50%)', 'Low (50-70%)', 'Medium (70-85%)', 'High (85-95%)', 'Very High (95-100%)'])\n",
    "\n",
    "print(\"Confidence distribution:\")\n",
    "for category, count in confidence_distribution.value_counts().sort_index().items():\n",
    "    percentage = (count / len(train_data_cleaned)) * 100\n",
    "    print(f\"  {category}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Most improved brands (consolidation effect)\n",
    "print(f\"\\nBrand Consolidation Analysis:\")\n",
    "print(\"-\" * 20)\n",
    "original_counts = train_data['Brand'].value_counts()\n",
    "cleaned_counts = train_data_cleaned['Brand_cleaned'].value_counts()\n",
    "\n",
    "consolidated_brands = []\n",
    "for cleaned_brand in cleaned_counts.index:\n",
    "    original_variants = train_data_cleaned[train_data_cleaned['Brand_cleaned'] == cleaned_brand]['Brand'].unique()\n",
    "    if len(original_variants) > 1:\n",
    "        consolidated_brands.append({\n",
    "            'cleaned_brand': cleaned_brand,\n",
    "            'variants': list(original_variants),\n",
    "            'count': len(original_variants),\n",
    "            'total_cars': cleaned_counts[cleaned_brand]\n",
    "        })\n",
    "\n",
    "# Sort by number of variants consolidated\n",
    "consolidated_brands.sort(key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "print(\"Top brands with most variants consolidated:\")\n",
    "for i, brand_info in enumerate(consolidated_brands[:5], 1):\n",
    "    print(f\"{i}. {brand_info['cleaned_brand']} ({brand_info['total_cars']} cars)\")\n",
    "    print(f\"   Consolidated {brand_info['count']} variants: {brand_info['variants']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total consolidation impact:\")\n",
    "print(f\"  Brands reduced from {train_data['Brand'].nunique()} to {train_data_cleaned['Brand_cleaned'].nunique()}\")\n",
    "print(f\"  Reduction: {train_data['Brand'].nunique() - train_data_cleaned['Brand_cleaned'].nunique()} brands (-{((train_data['Brand'].nunique() - train_data_cleaned['Brand_cleaned'].nunique()) / train_data['Brand'].nunique() * 100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9546ba0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
