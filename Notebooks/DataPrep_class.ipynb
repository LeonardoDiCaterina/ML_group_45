{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c024215",
   "metadata": {},
   "source": [
    "# DataPrep Class - Advanced Data Preprocessing Pipeline\n",
    "\n",
    "A comprehensive, configurable data preprocessing class for machine learning workflows with support for feature engineering, missing value handling, outlier detection, and custom transformations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Installation & Imports](#installation--imports)\n",
    "3. [Core Features](#core-features)\n",
    "4. [Basic Usage](#basic-usage)\n",
    "5. [Advanced Features](#advanced-features)\n",
    "6. [Testing Suite](#testing-suite)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `DataPrep` class provides a sklearn-like interface for data preprocessing with these key advantages:\n",
    "\n",
    "- **Consistent Processing**: Fit once on training data, apply same transformations to test/validation\n",
    "- **Feature Engineering**: Create new features by combining existing ones\n",
    "- **Flexible Configuration**: JSON-like configuration for each feature\n",
    "- **Custom Transformations**: Support for any callable function\n",
    "- **Multiple Outlier Methods**: IQR and Z-score based detection\n",
    "- **Error Handling**: Graceful handling of missing features and failed transformations\n",
    "\n",
    "---\n",
    "\n",
    "## Installation & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ed6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Dict, Any, Optional, Union, Callable, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ce24e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Core Features\n",
    "\n",
    "### Feature Configuration Options\n",
    "\n",
    "Each feature can be configured with the following options:\n",
    "\n",
    "| Parameter | Type | Description | Options |\n",
    "|-----------|------|-------------|---------|\n",
    "| `fill_na` | str/float | Missing value strategy | `'mean'`, `'median'`, `'mode'`, or numeric value |\n",
    "| `outlier_method` | str | Outlier detection method | `'iqr'`, `'zscore'` |\n",
    "| `outlier_action` | str | How to handle outliers | `'clip'`, `'remove'` |\n",
    "| `transform` | callable | Custom transformation function | Any function that takes a Series |\n",
    "| `zscore_threshold` | float | Z-score threshold (if using zscore) | Default: 3.0 |\n",
    "\n",
    "### Combined Features\n",
    "\n",
    "Create new features by combining existing ones:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `parent_features` | list | List of existing feature names to combine |\n",
    "| `combine_func` | callable | Function that takes DataFrame and returns Series |\n",
    "| `fill_na` | str/float | How to handle missing values in new feature |\n",
    "| `transform` | callable | Transformation to apply after combination |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8439499",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "## DataPrep Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7174f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Optional, Union, Callable, List\n",
    "\n",
    "class DataPrep:\n",
    "    def __init__(self, target_column: str = 'price'):\n",
    "        self.target_column = target_column\n",
    "        self.feature_configs = {}\n",
    "        self.fitted_params = {}\n",
    "        \n",
    "    def set_feature_config(self, feature_name: str, config: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Configure cleaning settings for a specific feature.\n",
    "        \n",
    "        Args:\n",
    "            feature_name: Name of the feature to configure\n",
    "            config: Dictionary with cleaning configuration\n",
    "                   For existing features:\n",
    "                   {'fill_na': 'median', 'transform': lambda x: np.log1p(x), 'outlier_method': 'iqr'}\n",
    "                   \n",
    "                   For new combined features:\n",
    "                   {\n",
    "                       'parent_features': ['feature1', 'feature2'],\n",
    "                       'combine_func': lambda df: df['feature1'] / df['feature2'],\n",
    "                       'fill_na': 'mean',\n",
    "                       'transform': lambda x: np.log1p(x),\n",
    "                       'outlier_method': 'iqr'\n",
    "                   }\n",
    "        \"\"\"\n",
    "        self.feature_configs[feature_name] = config\n",
    "        \n",
    "    def set_multiple_configs(self, configs: Dict[str, Dict[str, Any]]):\n",
    "        \"\"\"Set configurations for multiple features at once.\"\"\"\n",
    "        for feature_name, config in configs.items():\n",
    "            self.set_feature_config(feature_name, config)\n",
    "    \n",
    "    def fit(self, train_data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Fit the cleaning parameters on training data.\n",
    "        This calculates means, medians, IQR bounds, etc. based on training data.\n",
    "        \"\"\"\n",
    "        X = train_data.drop(columns=[self.target_column])\n",
    "        \n",
    "        # First, create any new combined features\n",
    "        X_with_new_features = self._create_combined_features(X)\n",
    "        \n",
    "        for feature_name, config in self.feature_configs.items():\n",
    "            if feature_name not in X_with_new_features.columns:\n",
    "                print(f\"Warning: Feature '{feature_name}' not found in data after feature creation\")\n",
    "                continue\n",
    "                \n",
    "            feature_params = {}\n",
    "            \n",
    "            # Store parent features if this is a combined feature\n",
    "            if 'parent_features' in config:\n",
    "                feature_params['parent_features'] = config['parent_features']\n",
    "                feature_params['combine_func'] = config['combine_func']\n",
    "            \n",
    "            # Handle missing value parameters\n",
    "            if 'fill_na' in config:\n",
    "                fill_method = config['fill_na']\n",
    "                if fill_method == 'mean':\n",
    "                    feature_params['fill_value'] = X_with_new_features[feature_name].mean()\n",
    "                elif fill_method == 'median':\n",
    "                    feature_params['fill_value'] = X_with_new_features[feature_name].median()\n",
    "                elif fill_method == 'mode':\n",
    "                    mode_val = X_with_new_features[feature_name].mode()\n",
    "                    feature_params['fill_value'] = mode_val.iloc[0] if not mode_val.empty else 0\n",
    "                elif isinstance(fill_method, (int, float)):\n",
    "                    feature_params['fill_value'] = fill_method\n",
    "                    \n",
    "            # Handle outlier detection parameters\n",
    "            if 'outlier_method' in config:\n",
    "                if config['outlier_method'] == 'iqr':\n",
    "                    Q1 = X_with_new_features[feature_name].quantile(0.25)\n",
    "                    Q3 = X_with_new_features[feature_name].quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    feature_params['outlier_lower'] = Q1 - 1.5 * IQR\n",
    "                    feature_params['outlier_upper'] = Q3 + 1.5 * IQR\n",
    "                elif config['outlier_method'] == 'zscore':\n",
    "                    mean = X_with_new_features[feature_name].mean()\n",
    "                    std = X_with_new_features[feature_name].std()\n",
    "                    threshold = config.get('zscore_threshold', 3)\n",
    "                    feature_params['outlier_lower'] = mean - threshold * std\n",
    "                    feature_params['outlier_upper'] = mean + threshold * std\n",
    "            \n",
    "            # Store transformation function\n",
    "            if 'transform' in config:\n",
    "                if callable(config['transform']):\n",
    "                    feature_params['transform_func'] = config['transform']\n",
    "                else:\n",
    "                    raise ValueError(f\"Transform for feature '{feature_name}' must be a callable function\")\n",
    "                \n",
    "            self.fitted_params[feature_name] = feature_params\n",
    "            \n",
    "    def _create_combined_features(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create new features by combining existing ones based on configurations.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame with original features\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with original + new combined features\n",
    "        \"\"\"\n",
    "        data_copy = data.copy()\n",
    "        \n",
    "        for feature_name, config in self.feature_configs.items():\n",
    "            if 'parent_features' in config and 'combine_func' in config:\n",
    "                parent_features = config['parent_features']\n",
    "                combine_func = config['combine_func']\n",
    "                \n",
    "                # Check if all parent features exist\n",
    "                missing_parents = [f for f in parent_features if f not in data_copy.columns]\n",
    "                if missing_parents:\n",
    "                    print(f\"Warning: Parent features {missing_parents} not found for combined feature '{feature_name}'\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Apply the combination function\n",
    "                    data_copy[feature_name] = combine_func(data_copy)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to create combined feature '{feature_name}': {e}\")\n",
    "                    \n",
    "        return data_copy\n",
    "    \n",
    "    def clean_feature(self, data: pd.DataFrame, feature_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply cleaning to a specific feature in the given data.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame to clean\n",
    "            feature_name: Name of the feature to clean\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with the cleaned feature\n",
    "        \"\"\"\n",
    "        if feature_name not in self.fitted_params:\n",
    "            print(f\"Warning: No configuration found for feature '{feature_name}'\")\n",
    "            return data\n",
    "            \n",
    "        data_copy = data.copy()\n",
    "        params = self.fitted_params[feature_name]\n",
    "        \n",
    "        # Create combined feature if needed\n",
    "        if 'parent_features' in params and 'combine_func' in params:\n",
    "            parent_features = params['parent_features']\n",
    "            missing_parents = [f for f in parent_features if f not in data_copy.columns]\n",
    "            if missing_parents:\n",
    "                print(f\"Warning: Parent features {missing_parents} not found for combined feature '{feature_name}'\")\n",
    "                return data_copy\n",
    "            \n",
    "            try:\n",
    "                data_copy[feature_name] = params['combine_func'](data_copy)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to create combined feature '{feature_name}': {e}\")\n",
    "                return data_copy\n",
    "        \n",
    "        if feature_name not in data_copy.columns:\n",
    "            print(f\"Warning: Feature '{feature_name}' not found in data after creation attempt\")\n",
    "            return data_copy\n",
    "        \n",
    "        # Handle missing values\n",
    "        if 'fill_value' in params:\n",
    "            data_copy[feature_name] = data_copy[feature_name].fillna(params['fill_value'])\n",
    "            \n",
    "        # Handle outliers\n",
    "        if 'outlier_lower' in params and 'outlier_upper' in params:\n",
    "            outlier_method = self.feature_configs[feature_name].get('outlier_action', 'clip')\n",
    "            \n",
    "            if outlier_method == 'clip':\n",
    "                data_copy[feature_name] = data_copy[feature_name].clip(\n",
    "                    lower=params['outlier_lower'], \n",
    "                    upper=params['outlier_upper']\n",
    "                )\n",
    "            elif outlier_method == 'remove':\n",
    "                mask = (data_copy[feature_name] >= params['outlier_lower']) & \\\n",
    "                       (data_copy[feature_name] <= params['outlier_upper'])\n",
    "                data_copy = data_copy[mask]\n",
    "                \n",
    "        # Apply custom transformation function\n",
    "        if 'transform_func' in params:\n",
    "            try:\n",
    "                data_copy[feature_name] = params['transform_func'](data_copy[feature_name])\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Transform function failed for feature '{feature_name}': {e}\")\n",
    "                \n",
    "        return data_copy\n",
    "    \n",
    "    def clean_data(self, data: pd.DataFrame, features: Optional[list] = None) -> tuple:\n",
    "        \"\"\"\n",
    "        Apply cleaning to specified features or all configured features.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame to clean\n",
    "            features: List of features to clean. If None, cleans all configured features.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (X_clean, y) where X_clean is cleaned features and y is target\n",
    "        \"\"\"\n",
    "        if features is None:\n",
    "            features = list(self.fitted_params.keys())\n",
    "            \n",
    "        data_clean = data.copy()\n",
    "        \n",
    "        # First create all combined features, then clean them\n",
    "        for feature in features:\n",
    "            data_clean = self.clean_feature(data_clean, feature)\n",
    "            \n",
    "        # Split into X and y\n",
    "        y = data_clean[self.target_column] if self.target_column in data_clean.columns else None\n",
    "        X = data_clean.drop(columns=[self.target_column]) if self.target_column in data_clean.columns else data_clean\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def get_feature_info(self, feature_name: str = None):\n",
    "        \"\"\"Get information about configured features and their fitted parameters.\"\"\"\n",
    "        if feature_name:\n",
    "            if feature_name in self.feature_configs:\n",
    "                info = {\n",
    "                    'config': self.feature_configs[feature_name].copy(),\n",
    "                    'fitted_params': self.fitted_params.get(feature_name, {}).copy()\n",
    "                }\n",
    "                # Replace functions with descriptions for readability\n",
    "                if 'transform' in info['config'] and callable(info['config']['transform']):\n",
    "                    info['config']['transform'] = f\"<function {info['config']['transform'].__name__}>\"\n",
    "                if 'combine_func' in info['config'] and callable(info['config']['combine_func']):\n",
    "                    info['config']['combine_func'] = f\"<function {info['config']['combine_func'].__name__}>\"\n",
    "                if 'transform_func' in info['fitted_params']:\n",
    "                    info['fitted_params']['transform_func'] = f\"<function {info['fitted_params']['transform_func'].__name__}>\"\n",
    "                if 'combine_func' in info['fitted_params']:\n",
    "                    info['fitted_params']['combine_func'] = f\"<function {info['fitted_params']['combine_func'].__name__}>\"\n",
    "                return info\n",
    "            else:\n",
    "                return f\"No configuration found for feature '{feature_name}'\"\n",
    "        else:\n",
    "            return {\n",
    "                'configured_features': list(self.feature_configs.keys()),\n",
    "                'fitted_features': list(self.fitted_params.keys())\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20572719",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Basic Usage\n",
    "\n",
    "### 1. Simple Feature Cleaning\n",
    "\n",
    "Basic example showing individual feature configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79277d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "   carID   Brand      model    year  price transmission  mileage fuelType  \\\n",
      "0  69512      VW       Golf  2016.0  22290    Semi-Auto  28421.0   Petrol   \n",
      "1  53000  Toyota      Yaris  2019.0  13790       Manual   4589.0   Petrol   \n",
      "2   6366    Audi         Q2  2019.0  24990    Semi-Auto   3624.0   Petrol   \n",
      "3  29021    Ford     FIESTA  2018.0  12500        anual   9102.0   Petrol   \n",
      "4  10062     BMW   2 Series  2019.0  22995       Manual   1000.0   Petrol   \n",
      "\n",
      "     tax        mpg  engineSize  paintQuality%  previousOwners  hasDamage  \n",
      "0    NaN  11.417268         2.0           63.0        4.000000        0.0  \n",
      "1  145.0  47.900000         1.5           50.0        1.000000        0.0  \n",
      "2  145.0  40.900000         1.5           56.0        4.000000        0.0  \n",
      "3  145.0  65.700000         1.0           50.0       -2.340306        0.0  \n",
      "4  145.0  42.800000         1.5           97.0        3.000000        0.0  \n"
     ]
    }
   ],
   "source": [
    "# Load sample data\n",
    "train_relative_path = '../Data/train.csv'\n",
    "test_relative_path = '../Data/test.csv'\n",
    "train_data = pd.read_csv(train_relative_path)\n",
    "test_data = pd.read_csv(test_relative_path)\n",
    "\n",
    "print(\"Sample data:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a73b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (75973, 13)\n",
      "Features cleaned: ['mileage', 'year', 'engineSize']\n"
     ]
    }
   ],
   "source": [
    "def log_transform(x):\n",
    "    \"\"\"Custom log transformation with safety checks\"\"\"\n",
    "    return np.log1p(np.abs(x) + 1)\n",
    "\n",
    "# Configure basic cleaning for individual features\n",
    "basic_configs = {\n",
    "    'mileage': {\n",
    "        'fill_na': 'median',\n",
    "        'transform': log_transform,\n",
    "        'outlier_method': 'iqr',\n",
    "        'outlier_action': 'clip'\n",
    "    },\n",
    "    'year': {\n",
    "        'fill_na': 'mean',\n",
    "        'transform': lambda x: 2025 - x,  # Convert to car age\n",
    "        'outlier_method': 'zscore',\n",
    "        'zscore_threshold': 2.5,\n",
    "        'outlier_action': 'clip'\n",
    "    },\n",
    "    'engineSize': {\n",
    "        'fill_na': 1.6,  # Domain-specific default\n",
    "        'transform': lambda x: np.log(x + 1) * 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize and fit the preprocessor\n",
    "data_prepper = DataPrep(target_column='price')\n",
    "data_prepper.set_multiple_configs(basic_configs)\n",
    "data_prepper.fit(train_data)\n",
    "\n",
    "# Clean the data\n",
    "X_train_clean, y_train = data_prepper.clean_data(train_data)\n",
    "X_test_clean, _ = data_prepper.clean_data(test_data)\n",
    "\n",
    "print(f\"Training shape: {X_train_clean.shape}\")\n",
    "print(f\"Features cleaned: {list(basic_configs.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18291525",
   "metadata": {},
   "source": [
    "### 2. Inspect Configuration Results\n",
    "\n",
    "View fitted parameters and configuration details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fdcf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mileage configuration:\n",
      "{'config': {'fill_na': 'median', 'transform': '<function log_transform>', 'outlier_method': 'iqr', 'outlier_action': 'clip'}, 'fitted_params': {'fill_value': np.float64(17300.0), 'outlier_lower': np.float64(-30083.125), 'outlier_upper': np.float64(69933.875), 'transform_func': '<function log_transform>'}}\n",
      "\n",
      "All configured features:\n",
      "{'configured_features': ['mileage', 'year', 'engineSize'], 'fitted_features': ['mileage', 'year', 'engineSize']}\n"
     ]
    }
   ],
   "source": [
    "# Get information about specific features\n",
    "print(\"Mileage configuration:\")\n",
    "print(data_prepper.get_feature_info('mileage'))\n",
    "\n",
    "print(\"\\nAll configured features:\")\n",
    "print(data_prepper.get_feature_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d79bfc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced Features\n",
    "\n",
    "### Feature Engineering with Combined Features\n",
    "\n",
    "Create sophisticated new features by combining existing ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f7660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features:\n",
      " ['carID', 'Brand', 'model', 'year', 'price', 'transmission', 'mileage', 'fuelType', 'tax', 'mpg', 'engineSize', 'paintQuality%', 'previousOwners', 'hasDamage']\n",
      "--------------------------------------------------\n",
      "Features after engineering:\n",
      " ['carID', 'Brand', 'model', 'year', 'transmission', 'mileage', 'fuelType', 'tax', 'mpg', 'engineSize', 'paintQuality%', 'previousOwners', 'hasDamage', 'mileage_per_year', 'power_efficiency', 'luxury_score']\n",
      "New features created:\n",
      " - mileage_per_year: dtype=float64\n",
      " - power_efficiency: dtype=float64\n",
      " - luxury_score: dtype=float64\n",
      "Features after engineering:\n",
      " ['carID', 'Brand', 'model', 'year', 'transmission', 'mileage', 'fuelType', 'tax', 'mpg', 'engineSize', 'paintQuality%', 'previousOwners', 'hasDamage', 'mileage_per_year', 'power_efficiency', 'luxury_score']\n",
      "New features created:\n",
      " - mileage_per_year: dtype=float64\n",
      " - power_efficiency: dtype=float64\n",
      " - luxury_score: dtype=float64\n"
     ]
    }
   ],
   "source": [
    "def log_transform(x):\n",
    "    \"\"\"Enhanced log transformation with safety checks\"\"\"\n",
    "    return np.log1p(np.abs(x) + 1)\n",
    "\n",
    "# Advanced configuration with feature engineering\n",
    "advanced_configs = {\n",
    "    # Base feature cleaning\n",
    "    'mileage': {\n",
    "        'fill_na': 'median',\n",
    "        'transform': log_transform,\n",
    "        'outlier_method': 'iqr',\n",
    "        'outlier_action': 'clip'\n",
    "    },\n",
    "    'year': {\n",
    "        'fill_na': 'mean',\n",
    "        'transform': lambda x: 2025 - x,\n",
    "        'outlier_method': 'zscore',\n",
    "        'zscore_threshold': 2.5,\n",
    "        'outlier_action': 'clip'\n",
    "    },\n",
    "    'engineSize': {\n",
    "        'fill_na': 1.6,\n",
    "        'transform': lambda x: np.log(x + 1) * 2,\n",
    "    },\n",
    "    \n",
    "    # Engineered Features\n",
    "    'mileage_per_year': {\n",
    "        'parent_features': ['mileage', 'year'],\n",
    "        'combine_func': lambda df: df['mileage'] / (2025 - df['year'] + 1),\n",
    "        'fill_na': 'median',\n",
    "        'transform': lambda x: np.sqrt(x),\n",
    "        'outlier_method': 'iqr',\n",
    "        'outlier_action': 'clip'\n",
    "    },\n",
    "    'power_efficiency': {\n",
    "        'parent_features': ['engineSize', 'year'],\n",
    "        'combine_func': lambda df: df['engineSize'] * 100 / (2025 - df['year'] + 50),\n",
    "        'fill_na': 'mean',\n",
    "        'transform': log_transform,\n",
    "    },\n",
    "    'luxury_score': {\n",
    "        'parent_features': ['engineSize', 'mileage', 'year'],\n",
    "        'combine_func': lambda df: (df['engineSize'] * 10) - (df['mileage'] / 1000) + (df['year'] - 2000),\n",
    "        'fill_na': 'median',\n",
    "        'outlier_method': 'zscore',\n",
    "        'zscore_threshold': 2,\n",
    "        'outlier_action': 'clip'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Original features:\\n\", train_data.columns.tolist())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Apply advanced preprocessing\n",
    "advanced_prepper = DataPrep(target_column='price')\n",
    "advanced_prepper.set_multiple_configs(advanced_configs)\n",
    "advanced_prepper.fit(train_data)\n",
    "\n",
    "# Create train/validation split\n",
    "X_train, X_val = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Clean all datasets\n",
    "X_train_clean, y_train = advanced_prepper.clean_data(X_train)\n",
    "X_val_clean, y_val = advanced_prepper.clean_data(X_val)\n",
    "X_test_final, _ = advanced_prepper.clean_data(test_data)\n",
    "\n",
    "print(\"Features after engineering:\\n\", X_train_clean.columns.tolist())\n",
    "new_features = [f for f in X_train_clean.columns if f not in train_data.columns]\n",
    "if new_features:\n",
    "    print(\"New features created:\")\n",
    "    for f in new_features:\n",
    "        print(f\" - {f}: dtype={X_train_clean[f].dtype}\")\n",
    "else:\n",
    "    print(\"No new features created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d4075",
   "metadata": {},
   "source": [
    "### Feature Engineering Results\n",
    "\n",
    "Inspect the newly created features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2d5b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined feature details:\n",
      "\n",
      "mileage_per_year:\n",
      "{'config': {'parent_features': ['mileage', 'year'], 'combine_func': '<function <lambda>>', 'fill_na': 'median', 'transform': '<function <lambda>>', 'outlier_method': 'iqr', 'outlier_action': 'clip'}, 'fitted_params': {'parent_features': ['mileage', 'year'], 'combine_func': '<function <lambda>>', 'fill_value': np.float64(1998.0), 'outlier_lower': np.float64(-2555.25), 'outlier_upper': np.float64(6858.75), 'transform_func': '<function <lambda>>'}}\n",
      "\n",
      "power_efficiency:\n",
      "{'config': {'parent_features': ['engineSize', 'year'], 'combine_func': '<function <lambda>>', 'fill_na': 'mean', 'transform': '<function log_transform>'}, 'fitted_params': {'parent_features': ['engineSize', 'year'], 'combine_func': '<function <lambda>>', 'fill_value': np.float64(2.8696735843366508), 'transform_func': '<function log_transform>'}}\n",
      "\n",
      "luxury_score:\n",
      "{'config': {'parent_features': ['engineSize', 'mileage', 'year'], 'combine_func': '<function <lambda>>', 'fill_na': 'median', 'outlier_method': 'zscore', 'zscore_threshold': 2, 'outlier_action': 'clip'}, 'fitted_params': {'parent_features': ['engineSize', 'mileage', 'year'], 'combine_func': '<function <lambda>>', 'fill_value': np.float64(15.0), 'outlier_lower': np.float64(-36.84201381696674), 'outlier_upper': np.float64(58.248975532586755)}}\n",
      "\n",
      "Missing values after processing: 21193\n",
      "Shape: Train (60778, 16), Val (15195, 16), Test (32567, 16)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the engineered features\n",
    "print(\"Combined feature details:\")\n",
    "for feature in ['mileage_per_year', 'power_efficiency', 'luxury_score']:\n",
    "    if feature in advanced_prepper.fitted_params:\n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(advanced_prepper.get_feature_info(feature))\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values after processing: {X_train_clean.isna().sum().sum()}\")\n",
    "print(f\"Shape: Train {X_train_clean.shape}, Val {X_val_clean.shape}, Test {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881ec54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Testing Suite\n",
    "\n",
    "### Comprehensive Unit Tests\n",
    "\n",
    "I asked chatgpt to create some automated testing ensures the DataPrep class works correctly across various scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "200c5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "import warnings\n",
    "\n",
    "class TestDataPrep(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        \"\"\"Set up test data before each test\"\"\"\n",
    "        # Create sample data for testing\n",
    "        np.random.seed(42)\n",
    "        self.sample_data = pd.DataFrame({\n",
    "            'feature1': [1, 2, np.nan, 4, 5, 100, 7, 8, 9, 10],  # Has missing values and outlier\n",
    "            'feature2': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'feature3': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'categorical_feature': ['A', 'B', 'A', 'C', np.nan, 'B', 'A', 'C', 'B', 'A'],\n",
    "            'price': [1000, 2000, 1500, 3000, 2500, 5000, 3500, 4000, 4500, 5500]\n",
    "        })\n",
    "        \n",
    "        # Create another dataset for testing consistency\n",
    "        self.test_data = pd.DataFrame({\n",
    "            'feature1': [1.5, 2.5, 3.5, np.nan, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5],\n",
    "            'feature2': [15, 25, 35, 45, 55, 65, 75, 85, 95, 105],\n",
    "            'feature3': [0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95, 1.05],\n",
    "            'categorical_feature': ['A', 'B', np.nan, 'C', 'B', 'A', 'C', 'A', 'B', 'C'],\n",
    "            'price': [1100, 2100, 1600, 3100, 2600, 5100, 3600, 4100, 4600, 5600]\n",
    "        })\n",
    "    \n",
    "    def test_initialization(self):\n",
    "        \"\"\"Test DataPrep initialization\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        self.assertEqual(dp.target_column, 'price')\n",
    "        self.assertEqual(dp.feature_configs, {})\n",
    "        self.assertEqual(dp.fitted_params, {})\n",
    "        \n",
    "        # Test custom target column\n",
    "        dp_custom = DataPrep(target_column='custom_target')\n",
    "        self.assertEqual(dp_custom.target_column, 'custom_target')\n",
    "    \n",
    "    def test_set_feature_config(self):\n",
    "        \"\"\"Test setting individual feature configurations\"\"\"\n",
    "        dp = DataPrep()\n",
    "        config = {\n",
    "            'fill_na': 'median',\n",
    "            'transform': lambda x: np.log1p(x),\n",
    "            'outlier_method': 'iqr'\n",
    "        }\n",
    "        \n",
    "        dp.set_feature_config('feature1', config)\n",
    "        self.assertEqual(dp.feature_configs['feature1'], config)\n",
    "    \n",
    "    def test_set_multiple_configs(self):\n",
    "        \"\"\"Test setting multiple feature configurations\"\"\"\n",
    "        dp = DataPrep()\n",
    "        configs = {\n",
    "            'feature1': {'fill_na': 'mean'},\n",
    "            'feature2': {'fill_na': 'median', 'transform': lambda x: x**2}\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        self.assertEqual(len(dp.feature_configs), 2)\n",
    "        self.assertIn('feature1', dp.feature_configs)\n",
    "        self.assertIn('feature2', dp.feature_configs)\n",
    "    \n",
    "    def test_fit_basic_operations(self):\n",
    "        \"\"\"Test fitting with basic operations\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        configs = {\n",
    "            'feature1': {\n",
    "                'fill_na': 'mean',\n",
    "                'outlier_method': 'iqr',\n",
    "                'transform': lambda x: np.log1p(x)\n",
    "            },\n",
    "            'feature2': {\n",
    "                'fill_na': 'median',\n",
    "                'outlier_method': 'zscore',\n",
    "                'zscore_threshold': 2.0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        # Check that parameters were fitted\n",
    "        self.assertIn('feature1', dp.fitted_params)\n",
    "        self.assertIn('feature2', dp.fitted_params)\n",
    "        \n",
    "        # Check specific fitted parameters\n",
    "        feature1_params = dp.fitted_params['feature1']\n",
    "        self.assertIn('fill_value', feature1_params)\n",
    "        self.assertIn('outlier_lower', feature1_params)\n",
    "        self.assertIn('outlier_upper', feature1_params)\n",
    "        self.assertIn('transform_func', feature1_params)\n",
    "    \n",
    "    def test_fill_na_methods(self):\n",
    "        \"\"\"Test different fill_na methods\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        configs = {\n",
    "            'feature1': {'fill_na': 'mean'},\n",
    "            'feature2': {'fill_na': 'median'},\n",
    "            'categorical_feature': {'fill_na': 'mode'},\n",
    "            'feature3': {'fill_na': 0.5}  # Specific value\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        # Check that fill values were calculated correctly\n",
    "        expected_mean = self.sample_data['feature1'].mean()\n",
    "        expected_median = self.sample_data['feature2'].median()\n",
    "        expected_mode = self.sample_data['categorical_feature'].mode().iloc[0]\n",
    "        \n",
    "        self.assertAlmostEqual(dp.fitted_params['feature1']['fill_value'], expected_mean)\n",
    "        self.assertAlmostEqual(dp.fitted_params['feature2']['fill_value'], expected_median)\n",
    "        self.assertEqual(dp.fitted_params['categorical_feature']['fill_value'], expected_mode)\n",
    "        self.assertEqual(dp.fitted_params['feature3']['fill_value'], 0.5)\n",
    "    \n",
    "    def test_outlier_methods(self):\n",
    "        \"\"\"Test different outlier detection methods\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        configs = {\n",
    "            'feature1': {'outlier_method': 'iqr'},\n",
    "            'feature2': {'outlier_method': 'zscore', 'zscore_threshold': 2.5}\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        # Check IQR method\n",
    "        Q1 = self.sample_data['feature1'].quantile(0.25)\n",
    "        Q3 = self.sample_data['feature1'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        expected_lower = Q1 - 1.5 * IQR\n",
    "        expected_upper = Q3 + 1.5 * IQR\n",
    "        \n",
    "        self.assertAlmostEqual(dp.fitted_params['feature1']['outlier_lower'], expected_lower)\n",
    "        self.assertAlmostEqual(dp.fitted_params['feature1']['outlier_upper'], expected_upper)\n",
    "        \n",
    "        # Check Z-score method\n",
    "        mean_f2 = self.sample_data['feature2'].mean()\n",
    "        std_f2 = self.sample_data['feature2'].std()\n",
    "        expected_lower_z = mean_f2 - 2.5 * std_f2\n",
    "        expected_upper_z = mean_f2 + 2.5 * std_f2\n",
    "        \n",
    "        self.assertAlmostEqual(dp.fitted_params['feature2']['outlier_lower'], expected_lower_z)\n",
    "        self.assertAlmostEqual(dp.fitted_params['feature2']['outlier_upper'], expected_upper_z)\n",
    "    \n",
    "    def test_clean_feature(self):\n",
    "        \"\"\"Test cleaning individual features\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        config = {\n",
    "            'fill_na': 'mean',\n",
    "            'transform': lambda x: x * 2,\n",
    "            'outlier_method': 'iqr',\n",
    "            'outlier_action': 'clip'\n",
    "        }\n",
    "        \n",
    "        dp.set_feature_config('feature1', config)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        # Clean the feature\n",
    "        cleaned_data = dp.clean_feature(self.sample_data, 'feature1')\n",
    "        \n",
    "        # Check that missing values were filled\n",
    "        self.assertFalse(cleaned_data['feature1'].isna().any())\n",
    "    \n",
    "    def test_clean_data_full_pipeline(self):\n",
    "        \"\"\"Test the complete data cleaning pipeline\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        configs = {\n",
    "            'feature1': {\n",
    "                'fill_na': 'median',\n",
    "                'transform': lambda x: np.log1p(x),\n",
    "                'outlier_method': 'iqr',\n",
    "                'outlier_action': 'clip'\n",
    "            },\n",
    "            'feature2': {\n",
    "                'fill_na': 'mean',\n",
    "                'outlier_method': 'zscore',\n",
    "                'zscore_threshold': 2.0,\n",
    "                'outlier_action': 'clip'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        X_clean, y_clean = dp.clean_data(self.sample_data)\n",
    "        \n",
    "        # Check that target column is separated correctly\n",
    "        self.assertNotIn('price', X_clean.columns)\n",
    "        self.assertEqual(len(y_clean), len(self.sample_data))\n",
    "        \n",
    "        # Check that configured features were cleaned\n",
    "        self.assertIn('feature1', X_clean.columns)\n",
    "        self.assertIn('feature2', X_clean.columns)\n",
    "        \n",
    "        # Check no missing values in cleaned features\n",
    "        self.assertFalse(X_clean['feature1'].isna().any())\n",
    "        self.assertFalse(X_clean['feature2'].isna().any())\n",
    "    \n",
    "    def test_combined_features(self):\n",
    "        \"\"\"Test creating and cleaning combined features\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        configs = {\n",
    "            'feature1': {'fill_na': 'mean'},\n",
    "            'feature2': {'fill_na': 'mean'},\n",
    "            'combined_feature': {\n",
    "                'parent_features': ['feature1', 'feature2'],\n",
    "                'combine_func': lambda df: df['feature1'] + df['feature2'],\n",
    "                'fill_na': 'median',\n",
    "                'transform': lambda x: x / 2\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        X_clean, y_clean = dp.clean_data(self.sample_data)\n",
    "        \n",
    "        # Check that combined feature was created\n",
    "        self.assertIn('combined_feature', X_clean.columns)\n",
    "        \n",
    "        # Check that no missing values exist\n",
    "        self.assertFalse(X_clean['combined_feature'].isna().any())\n",
    "    \n",
    "    def test_consistency_across_datasets(self):\n",
    "        \"\"\"Test that the same parameters are applied consistently across different datasets\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        configs = {\n",
    "            'feature1': {\n",
    "                'fill_na': 'mean',\n",
    "                'transform': lambda x: x * 2,\n",
    "                'outlier_method': 'iqr',\n",
    "                'outlier_action': 'clip'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(self.sample_data)  # Fit on first dataset\n",
    "        \n",
    "        # Get the fitted fill value\n",
    "        fitted_fill_value = dp.fitted_params['feature1']['fill_value']\n",
    "        \n",
    "        # Clean both datasets\n",
    "        X_train, _ = dp.clean_data(self.sample_data)\n",
    "        X_test, _ = dp.clean_data(self.test_data)\n",
    "        \n",
    "        # Both should have no missing values\n",
    "        self.assertFalse(X_train['feature1'].isna().any())\n",
    "        self.assertFalse(X_test['feature1'].isna().any())\n",
    "        \n",
    "        # The fill value should be consistent (from training data)\n",
    "        self.assertAlmostEqual(fitted_fill_value, self.sample_data['feature1'].mean())\n",
    "    \n",
    "    def test_error_handling(self):\n",
    "        \"\"\"Test error handling for various edge cases\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        # Test invalid transform function - this test should work with fit() method\n",
    "        dp.set_feature_config('feature1', {'fill_na': 'mean'})\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        # Test with invalid transform function\n",
    "        try:\n",
    "            dp.set_feature_config('feature1', {'transform': 'not_a_function'})\n",
    "            dp.fit(self.sample_data)\n",
    "        except ValueError:\n",
    "            pass  # Expected behavior\n",
    "        \n",
    "        # Test missing feature warning\n",
    "        dp2 = DataPrep(target_column='price')\n",
    "        dp2.set_feature_config('nonexistent_feature', {'fill_na': 'mean'})\n",
    "        with patch('builtins.print') as mock_print:\n",
    "            dp2.fit(self.sample_data)\n",
    "            # Should print warning about missing feature\n",
    "            mock_print.assert_called()\n",
    "        \n",
    "        # Test cleaning feature that wasn't configured\n",
    "        dp3 = DataPrep(target_column='price')\n",
    "        result = dp3.clean_feature(self.sample_data, 'unconfigured_feature')\n",
    "        pd.testing.assert_frame_equal(result, self.sample_data)\n",
    "    \n",
    "    def test_get_feature_info(self):\n",
    "        \"\"\"Test the get_feature_info method\"\"\"\n",
    "        dp = DataPrep(target_column='price')\n",
    "        \n",
    "        def custom_transform(x):\n",
    "            return x * 2\n",
    "        \n",
    "        config = {\n",
    "            'fill_na': 'mean',\n",
    "            'transform': custom_transform,\n",
    "            'outlier_method': 'iqr'\n",
    "        }\n",
    "        \n",
    "        dp.set_feature_config('feature1', config)\n",
    "        dp.fit(self.sample_data)\n",
    "        \n",
    "        # Test getting info for specific feature\n",
    "        info = dp.get_feature_info('feature1')\n",
    "        self.assertIn('config', info)\n",
    "        self.assertIn('fitted_params', info)\n",
    "        \n",
    "        # Test getting all features info\n",
    "        all_info = dp.get_feature_info()\n",
    "        self.assertIn('configured_features', all_info)\n",
    "        self.assertIn('fitted_features', all_info)\n",
    "        \n",
    "        # Test getting info for non-existent feature\n",
    "        no_info = dp.get_feature_info('nonexistent')\n",
    "        self.assertIsInstance(no_info, str)\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Run all tests and display results\"\"\"\n",
    "    print(\"Running DataPrep Class Tests...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create test suite - FIXED: correct method name\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestDataPrep)\n",
    "    \n",
    "    # Run tests with detailed output\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    result = runner.run(test_suite)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Tests run: {result.testsRun}\")\n",
    "    print(f\"Failures: {len(result.failures)}\")\n",
    "    print(f\"Errors: {len(result.errors)}\")\n",
    "    \n",
    "    if result.failures:\n",
    "        print(\"\\nFailures:\")\n",
    "        for test, traceback in result.failures:\n",
    "            print(f\"- {test}: {traceback}\")\n",
    "    \n",
    "    if result.errors:\n",
    "        print(\"\\nErrors:\")\n",
    "        for test, traceback in result.errors:\n",
    "            print(f\"- {test}: {traceback}\")\n",
    "    \n",
    "    if result.wasSuccessful():\n",
    "        print(\"\\n✅ All tests passed!\")\n",
    "    else:\n",
    "        print(f\"\\n❌ {len(result.failures + result.errors)} test(s) failed\")\n",
    "    \n",
    "    return result.wasSuccessful()\n",
    "\n",
    "# Additional integration tests\n",
    "def test_real_world_scenario():\n",
    "    \"\"\"Test a realistic data preprocessing scenario\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    print(\"Running Real-World Scenario Test\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Create realistic car data\n",
    "    np.random.seed(123)\n",
    "    car_data = pd.DataFrame({\n",
    "        'mileage': np.random.normal(50000, 30000, 100),\n",
    "        'year': np.random.choice(range(2000, 2024), 100),\n",
    "        'engineSize': np.random.normal(2.0, 0.8, 100),\n",
    "        'price': np.random.normal(15000, 8000, 100)\n",
    "    })\n",
    "    \n",
    "    # Add some missing values and outliers\n",
    "    car_data.loc[5:10, 'mileage'] = np.nan\n",
    "    car_data.loc[95:98, 'engineSize'] = np.nan\n",
    "    car_data.loc[2, 'mileage'] = 500000  # Outlier\n",
    "    car_data.loc[3, 'price'] = 100000    # Outlier\n",
    "    \n",
    "    # Configure preprocessing\n",
    "    dp = DataPrep(target_column='price')\n",
    "    \n",
    "    configs = {\n",
    "        'mileage': {\n",
    "            'fill_na': 'median',\n",
    "            'transform': lambda x: np.log1p(np.abs(x)+1),\n",
    "            'outlier_method': 'iqr',\n",
    "            'outlier_action': 'clip'\n",
    "        },\n",
    "        'year': {\n",
    "            'fill_na': 'mean',\n",
    "            'transform': lambda x: 2024 - x,  # Convert to age\n",
    "            'outlier_method': 'zscore',\n",
    "            'zscore_threshold': 3,\n",
    "            'outlier_action': 'clip'\n",
    "        },\n",
    "        'engineSize': {\n",
    "            'fill_na': 'mean',\n",
    "            'transform': lambda x: x ** 2,  # Square for non-linearity\n",
    "        },\n",
    "        'efficiency_score': {\n",
    "            'parent_features': ['mileage', 'year'],\n",
    "            'combine_func': lambda df: df['mileage'] / (2024 - df['year'] + 1),\n",
    "            'fill_na': 'median',\n",
    "            'transform': lambda x: np.sqrt(x),\n",
    "            'outlier_method': 'iqr',\n",
    "            'outlier_action': 'clip'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        dp.set_multiple_configs(configs)\n",
    "        dp.fit(car_data)\n",
    "        \n",
    "        # Clean the data\n",
    "        X_clean, y_clean = dp.clean_data(car_data)\n",
    "        X_clean = X_clean[list(configs.keys())]  # Keep only configured features\n",
    "        # Verify results\n",
    "        print(f\"Original shape: {car_data.shape}\")\n",
    "        print(f\"Cleaned features shape: {X_clean.shape}\")\n",
    "        print(f\"Target shape: {y_clean.shape}\")\n",
    "        print(f\"Missing values in cleaned data: {X_clean.isna().sum().sum()}\")\n",
    "        print(f\"Features created: {X_clean.columns.tolist()}\")\n",
    "        \n",
    "        # Check that combined feature was created\n",
    "        assert 'efficiency_score' in X_clean.columns, \"Combined feature not created\"\n",
    "        \n",
    "        # Check no missing values\n",
    "        assert X_clean.isna().sum().sum() == 0, \"Missing values still present\"\n",
    "        \n",
    "        print(\"✅ Real-world scenario test passed!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Real-world scenario test failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c1ed1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_clean_data_full_pipeline (__main__.TestDataPrep.test_clean_data_full_pipeline)\n",
      "Test the complete data cleaning pipeline ... ok\n",
      "test_clean_feature (__main__.TestDataPrep.test_clean_feature)\n",
      "Test cleaning individual features ... ok\n",
      "test_combined_features (__main__.TestDataPrep.test_combined_features)\n",
      "Test creating and cleaning combined features ... ok\n",
      "ok\n",
      "test_clean_feature (__main__.TestDataPrep.test_clean_feature)\n",
      "Test cleaning individual features ... ok\n",
      "test_combined_features (__main__.TestDataPrep.test_combined_features)\n",
      "Test creating and cleaning combined features ... ok\n",
      "test_consistency_across_datasets (__main__.TestDataPrep.test_consistency_across_datasets)\n",
      "Test that the same parameters are applied consistently across different datasets ... ok\n",
      "test_consistency_across_datasets (__main__.TestDataPrep.test_consistency_across_datasets)\n",
      "Test that the same parameters are applied consistently across different datasets ... ok\n",
      "test_error_handling (__main__.TestDataPrep.test_error_handling)\n",
      "Test error handling for various edge cases ... ok\n",
      "test_fill_na_methods (__main__.TestDataPrep.test_fill_na_methods)\n",
      "Test different fill_na methods ... ok\n",
      "test_fit_basic_operations (__main__.TestDataPrep.test_fit_basic_operations)\n",
      "Test fitting with basic operations ... test_error_handling (__main__.TestDataPrep.test_error_handling)\n",
      "Test error handling for various edge cases ... ok\n",
      "test_fill_na_methods (__main__.TestDataPrep.test_fill_na_methods)\n",
      "Test different fill_na methods ... ok\n",
      "test_fit_basic_operations (__main__.TestDataPrep.test_fit_basic_operations)\n",
      "Test fitting with basic operations ... ok\n",
      "ok\n",
      "test_get_feature_info (__main__.TestDataPrep.test_get_feature_info)\n",
      "Test the get_feature_info method ... ok\n",
      "test_initialization (__main__.TestDataPrep.test_initialization)\n",
      "Test DataPrep initialization ... ok\n",
      "test_outlier_methods (__main__.TestDataPrep.test_outlier_methods)\n",
      "Test different outlier detection methods ... ok\n",
      "test_set_feature_config (__main__.TestDataPrep.test_set_feature_config)\n",
      "Test setting individual feature configurations ... ok\n",
      "test_get_feature_info (__main__.TestDataPrep.test_get_feature_info)\n",
      "Test the get_feature_info method ... ok\n",
      "test_initialization (__main__.TestDataPrep.test_initialization)\n",
      "Test DataPrep initialization ... ok\n",
      "test_outlier_methods (__main__.TestDataPrep.test_outlier_methods)\n",
      "Test different outlier detection methods ... ok\n",
      "test_set_feature_config (__main__.TestDataPrep.test_set_feature_config)\n",
      "Test setting individual feature configurations ... ok\n",
      "test_set_multiple_configs (__main__.TestDataPrep.test_set_multiple_configs)\n",
      "Test setting multiple feature configurations ... ok\n",
      "\n",
      "test_set_multiple_configs (__main__.TestDataPrep.test_set_multiple_configs)\n",
      "Test setting multiple feature configurations ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.100s\n",
      "\n",
      "OK\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.100s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DataPrep Class Tests...\n",
      "==================================================\n",
      "Warning: No configuration found for feature 'unconfigured_feature'\n",
      "\n",
      "==================================================\n",
      "Tests run: 12\n",
      "Failures: 0\n",
      "Errors: 0\n",
      "\n",
      "✅ All tests passed!\n",
      "\n",
      "==============================\n",
      "Running Real-World Scenario Test\n",
      "==============================\n",
      "Original shape: (100, 4)\n",
      "Cleaned features shape: (100, 4)\n",
      "Target shape: (100,)\n",
      "Missing values in cleaned data: 0\n",
      "Features created: ['mileage', 'year', 'engineSize', 'efficiency_score']\n",
      "✅ Real-world scenario test passed!\n",
      "\n",
      "🎉 All tests completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Run all tests\n",
    "if __name__ == \"__main__\":\n",
    "    success1 = run_tests()\n",
    "    success2 = test_real_world_scenario()\n",
    "    \n",
    "    if success1 and success2:\n",
    "        print(\"\\n🎉 All tests completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Some tests failed. Please check the output above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
